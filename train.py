# # full batchsize
# listcorr = [-0.15132908172606455, -0.6261881880884538, -0.6276183331207575, -0.6270146667306177, -0.6345326529783775, -0.6452351069988947, -0.6557021559148811, -0.6691605870432836, -0.6680301578224541, -0.6767741881048673, -0.6876113864094329, -0.670427717489059, -0.6821895182771012, -0.6891055089996432, -0.677168284959178, -0.6882611898946591, -0.6927541848399471, -0.6840462340563425, -0.6955433134588851, -0.699802988942691, -0.6903515726878384, -0.691079596356553, -0.6910064169765905, -0.7022810347756191, -0.6898344052430024, -0.6926570902738083, -0.6960137694640391, -0.7017828424920693, -0.6926547112691092, -0.7046763248803617, -0.7045712751316383, -0.6971859999447516, -0.700666627276732, -0.7064840860405548, -0.7134677866534105, -0.6988139691952479, -0.712758453179616, -0.7106060811922535, -0.7043963346239133, -0.704325379199133, -0.6977402894280141, -0.6982516516581188, -0.7093044075842098, -0.7045699566740528, -0.7058006960635468, -0.7112341719505509, -0.7075320851768305, -0.708621873610608, -0.7012137764067709, -0.6994871308984701, -0.7073185087928429, -0.7140453068084848, -0.7071742904439537, -0.702695954960438, -0.7040878327380405, -0.7082557210212717, -0.7122553318105755, -0.705227155527391, -0.7083680196931061, -0.7143367441366055, -0.7122583263792076, -0.7134150676958576, -0.7175246024853386, -0.7107993960996957, -0.7150261176463334, -0.7170082476944156, -0.717784823561188, -0.7162717063154554, -0.7051297518613707, -0.6999332759301161, -0.708694166011728, -0.707426203711237, -0.7212501057494436, -0.7137483618885028, -0.720405029814951, -0.7192553565229098, -0.7245890028020072, -0.7143509719700616, -0.7259446793853926, -0.72196549218664, -0.7143414858114465, -0.7273500737867316, -0.7253897395698824, -0.7267874364995022, -0.7204148184879123, -0.7172180100661388, -0.7219084435386769, -0.7266352001003703, -0.7353762481200519, -0.7180076364312683, -0.729090877558373, -0.7178314894438852, -0.7215377444305477, -0.7156105123813676, -0.7250923754300429, -0.7260206309124136, -0.7203935819465661, -0.7262210015290842, -0.7325874710388459, -0.7261851378223174, -0.7249529041303827, -0.7274438069348872, -0.7215426378238579, -0.7199021256345818, -0.7246708807171072, -0.721764388589603, -0.7312329600636055, -0.7238785865043643, -0.7223056361726442, -0.7293247728938896, -0.7293837318460983, -0.7175006348418695, -0.7295604207929234, -0.7289297791783725, -0.7355791836744934, -0.7327629624371222, -0.7296250400081252, -0.7307932021659636, -0.7262875896936551, -0.7372547392590304, -0.7296283348756976, -0.7310704856081621, -0.7311401130766269, -0.7348484907551008]

# batchsize 200
#listcorr = [-0.15132908172606455, -0.6261881880884538, -0.6276183331207575, -0.6270146667306177, -0.6345326529783775, -0.6452351069988947, -0.6557021559148811, -0.6691605870432836, -0.6680301578224541, -0.6767741881048673, -0.6876113864094329, -0.670427717489059, -0.6821895182771012, -0.6891055089996432, -0.677168284959178, -0.6882611898946591, -0.6927541848399471, -0.6840462340563425, -0.6955433134588851, -0.699802988942691, -0.6903515726878384, -0.691079596356553, -0.6910064169765905, -0.7022810347756191, -0.6898344052430024, -0.6926570902738083, -0.6960137694640391, -0.7017828424920693, -0.6926547112691092, -0.7046763248803617, -0.7045712751316383, -0.6971859999447516, -0.700666627276732, -0.7064840860405548, -0.7134677866534105, -0.6988139691952479, -0.712758453179616, -0.7106060811922535, -0.7043963346239133, -0.704325379199133, -0.6977402894280141, -0.6982516516581188, -0.7093044075842098, -0.7045699566740528, -0.7058006960635468, -0.7112341719505509, -0.7075320851768305, -0.708621873610608, -0.7012137764067709, -0.6994871308984701, -0.7073185087928429, -0.7140453068084848, -0.7071742904439537, -0.702695954960438, -0.7040878327380405, -0.7082557210212717, -0.7122553318105755, -0.705227155527391, -0.7083680196931061, -0.7143367441366055, -0.7122583263792076, -0.7134150676958576, -0.7175246024853386, -0.7107993960996957, -0.7150261176463334, -0.7170082476944156, -0.717784823561188, -0.7162717063154554, -0.7051297518613707, -0.6999332759301161, -0.708694166011728, -0.707426203711237, -0.7212501057494436, -0.7137483618885028, -0.720405029814951, -0.7192553565229098, -0.7245890028020072, -0.7143509719700616, -0.7259446793853926, -0.72196549218664, -0.7143414858114465, -0.7273500737867316, -0.7253897395698824, -0.7267874364995022, -0.7204148184879123, -0.7172180100661388, -0.7219084435386769, -0.7266352001003703, -0.7353762481200519, -0.7180076364312683, -0.729090877558373, -0.7178314894438852, -0.7215377444305477, -0.7156105123813676, -0.7250923754300429, -0.7260206309124136, -0.7203935819465661, -0.7262210015290842, -0.7325874710388459, -0.7261851378223174, -0.7249529041303827, -0.7274438069348872, -0.7215426378238579, -0.7199021256345818, -0.7246708807171072, -0.721764388589603, -0.7312329600636055, -0.7238785865043643, -0.7223056361726442, -0.7293247728938896, -0.7293837318460983, -0.7175006348418695, -0.7295604207929234, -0.7289297791783725, -0.7355791836744934, -0.7327629624371222, -0.7296250400081252, -0.7307932021659636, -0.7262875896936551, -0.7372547392590304, -0.7296283348756976, -0.7310704856081621, -0.7311401130766269, -0.7348484907551008, -0.7322104831953309, -0.7303925175347642, -0.7311447848243772, -0.7282161723419225, -0.7311533807226217, -0.7361659303547127, -0.7241346002606158, -0.7291824254253437, -0.7337658758109326, -0.7289417066663832, -0.7306387728016297, -0.7267939644352945, -0.7358933127414357, -0.7280616111070194, -0.7170713041248047, -0.7385752572485486, -0.7239914600055513, -0.7254325127666905, -0.7242385533975383, -0.7174550538827731, -0.7218847657042161, -0.728134501552692, -0.7268486725467317, -0.736330021191671, -0.7330938076502905, -0.7263425873464172, -0.7295418492272947, -0.7301172626396697, -0.7306136525710323, -0.7370167627567082, -0.7285904195402811, -0.7405340443005606, -0.7275157796210582, -0.7426077534494192, -0.7341017082107437, -0.7331822491469762, -0.72685603987521, -0.7243917795465369, -0.7315435207984127, -0.7296460329428884, -0.7298707084485624, -0.7260232128887576, -0.7286836967676769, -0.7289804583772558, -0.725456978709437, -0.7226189090432462, -0.7223977735350503, -0.7231602492314542, -0.7322791552790199, -0.7251424668891607, -0.7277504584858904, -0.7355966310874709, -0.7200441914395147, -0.7129379099710045, -0.7249141775731592, -0.7242241637067716, -0.7227116366422617, -0.7325542075304505, -0.738427445408638]
# print(len(listcorr))

#listcorr = [-0.15533635530745185, -0.6261101458625491, -0.6283672933462191, -0.6261341715173672, -0.635904753096498, -0.6478975616358452, -0.6546675117782986, -0.6696253830703839, -0.6676424000841114, -0.6761717976171625, -0.6891460193743165, -0.6720522358315661, -0.6842409049998647, -0.6941483266183958, -0.6819605041356567, -0.6921307305692801, -0.6974118244250612, -0.6877276293682595, -0.6975180166936966, -0.699362900982982, -0.6900176483424889, -0.6930444490784223, -0.6900437932974185, -0.7022671734019181, -0.6917734057659254, -0.6850279494457204, -0.6889707768594764, -0.6932684998402032, -0.6877374177079576, -0.6984572192619203, -0.6977660925568185, -0.6919893299160746, -0.6963702609467773, -0.7110312711090508, -0.7205724517474444, -0.6988695095967887, -0.7103223178901148, -0.7066052462875619, -0.7183075818913138, -0.7154377489551932, -0.7088756137953657, -0.707082142138999, -0.7226954733123476, -0.7103618835652266, -0.710930690475186, -0.7217952963201721, -0.7193970614884093, -0.7259399976426528, -0.7133274757373838, -0.7128356151291262, -0.7154447977837326, -0.7271007631430586, -0.7161603834335195, -0.7127408203499865, -0.72103956071462, -0.7295909300855787, -0.7251813288910407, -0.723708742721878, -0.7291789132139994, -0.7321391799272989, -0.7238789685287154, -0.7239828388735304, -0.7290574486054026, -0.7190759055488052, -0.7268529379218275, -0.7295493327303769, -0.719326426117973, -0.7127832694690167, -0.7081343451222445, -0.7065131788206702, -0.715821841409185, -0.722080445540987, -0.7300130252264722, -0.7207281466845149, -0.7280898054612912, -0.720801798098683, -0.7250909568675997, -0.7119285039302476, -0.726113803005629, -0.7271415484249357, -0.7215975739756065, -0.7314755145354167, -0.7326754556309272, -0.7373561786281022, -0.7316186259389661, -0.7269711812549527, -0.7305438509156079, -0.7297602094360042, -0.7322278678679339, -0.7188402182964757, -0.7260092248413066, -0.7212380007861936, -0.7199928423040254, -0.7195487094977885, -0.7299812831306096, -0.7265617483745203, -0.7204584789650719, -0.7366704242122137, -0.7366728313150994, -0.7337813087867479, -0.730352655202939, -0.7292820911732971, -0.731366939043279, -0.7349022022610685, -0.7391185612576011, -0.7245336486686268, -0.7331863340702224, -0.7221095343458427, -0.7253716737363578, -0.7315502539141884, -0.7385644233400107, -0.7262920080547155, -0.7367722807278155, -0.7335317742579606, -0.734376768138198, -0.7274861856941953, -0.7295416454063093, -0.7266225547336879, -0.7262479795518788, -0.7411803072563012, -0.7334723217023789, -0.7341838513197139, -0.7374189207732753, -0.7351296743634164, -0.7336338811810648, -0.7338541998680409, -0.7406476077746686, -0.7276144158411758, -0.7325229197730759, -0.7396219028386604, -0.7259892534279763, -0.7304469123426568, -0.7350522544493432, -0.7228350456023789, -0.7301829864874083, -0.7172696943588628, -0.7348903044358792, -0.7222424154705771, -0.7261585483793753, -0.7426148996208912, -0.7337249690815759, -0.7308640683353683, -0.7242940947492439, -0.7234057916406872, -0.719312194622353, -0.7213999530585097, -0.7252669089306982, -0.732979378704332, -0.7259948134705211, -0.7319181451572397, -0.7366920454938455, -0.7261610802057679, -0.7309284346017371, -0.7248037836775026, -0.7223095285647309, -0.7344917899730634, -0.7386419828369049, -0.7382249493112324, -0.7235095140972874, -0.7285999959671597, -0.7283231154072553, -0.7249224095759661, -0.7346789423566054, -0.7262801321101133, -0.7277181242464701, -0.7232375954513519, -0.7309342310423628, -0.7275165432865361, -0.7353190971392055, -0.7295745095022073, -0.7312914440959535, -0.7293742452976298, -0.7315788108505199, -0.7325199444992158, -0.7366893174956508, -0.7448652345342265, -0.7358246374616882, -0.7205132318815353, -0.7316860624961918, -0.7381617707113716, -0.7373395481581858, -0.7412414496867867, -0.7381463605949043, -0.727343797588766, -0.733157577208889, -0.7345744670215092, -0.7319864861348004, -0.7367309153899126, -0.7350468354255916, -0.7367584252314163, -0.7433702920935167, -0.7379441151891318, -0.7390694517903951, -0.7344170481288258, -0.7338432678871344, -0.728087459741582, -0.7258253927322968, -0.7306297970377919, -0.7386086550068616, -0.734365722784613, -0.7311782095740614, -0.7334200974576145, -0.7316173258498424, -0.7337711092000847, -0.744123869137413, -0.7292854244667494, -0.724250946411083, -0.7355387275644143, -0.7316615717644195, -0.73650073610019, -0.7306871333365231, -0.7321954919136741, -0.730651679024164, -0.7242531063991403, -0.7325696570666734, -0.7362554496938692, -0.7368883593731005, -0.7279935174280724, -0.7352899424439493, -0.7397167947227978, -0.7323178910719276, -0.7338978417652128, -0.7292883967093607, -0.7301663735949585, -0.7284732035739125, -0.7345060157268472, -0.7375749363963607, -0.7366771619026018, -0.7359848238405597, -0.734697853215732, -0.7402140491792555, -0.739662915994829, -0.7305752860228805, -0.7338728176234836, -0.7333197370482285, -0.7226010730019623, -0.7299278352647844, -0.7351490485649743, -0.7330053737411355, -0.7384412415068214, -0.7290788028806104, -0.7308166817167411, -0.7400889580692572, -0.7369077958851356, -0.7368065120184606, -0.7366975696626716, -0.7283614208000357, -0.7304548969387957, -0.7410350844626495, -0.7327387507517292, -0.7326293521204297, -0.7345619736113407, -0.7330552180880311, -0.7399797456808281, -0.7329315594057062, -0.7325176966498562, -0.7321556082194771, -0.7322160007019404, -0.7322588287991537, -0.7298668313195051, -0.7370649301792893, -0.7273000401714457, -0.7370061024269526, -0.7326937307730575, -0.728080650510039, -0.7318051586460459, -0.727677817445555, -0.7344931224758292, -0.7442197789924027, -0.7349297662039962, -0.7408154096682689, -0.7299924987336961, -0.7286478951865908, -0.7297289093413778, -0.7249140504215047, -0.7292789999960017, -0.7287270433381382, -0.721636306490651, -0.7242173314677913, -0.723706732390448, -0.7285221153843469, -0.7300421367974814, -0.7315375468317308, -0.7322222135409986, -0.7310963118782267, -0.7295820693349939, -0.7363596043311478, -0.7301533979511281, -0.7228855872508086, -0.7313262922937445, -0.7306431448678828, -0.7246376459781505, -0.7359440796831295, -0.7421340710042635, -0.7262991192462769, -0.7255823297331866, -0.732083255342759, -0.7343634234176973, -0.7442344203577347, -0.7331679455708824, -0.7320298776637933, -0.7390741669129385, -0.7451655556623324, -0.7323101210853794, -0.7308019433823384, -0.7303522346920117, -0.7333638187187286, -0.7310560373064654, -0.7409409975734187, -0.733218042447528, -0.7200879031737732, -0.7327797062874303, -0.736100279896075, -0.7331268570458398, -0.7394680968389663, -0.7319140026640074, -0.7217244847181753, -0.7335649216895374, -0.7376044078892213, -0.7326933928563996, -0.7232181730726509, -0.730412852388909, -0.7440457911996697, -0.7360736594346659, -0.7354299966530857, -0.7383332287880249, -0.7337374111314888, -0.7296309979008473, -0.7284379420303995, -0.7329284661993921, -0.7294880080233356, -0.7337168981050497, -0.7295624696038531, -0.7287819832620837, -0.7272461106168521, -0.7260812515005036, -0.7333546837337753, -0.7308767005619797, -0.7363504567060242, -0.7359583813151914, -0.7269802759051357, -0.7183017287307065, -0.722786896274011, -0.7334662035973616, -0.7349214014943678, -0.7220434359377704, -0.7286099944747805, -0.7327026816856219, -0.728646571996216, -0.7340420820415113, -0.7353365802820493, -0.737728287988515, -0.7390430346055445, -0.7381905854930361, -0.7395311168857688, -0.7420414653786228, -0.7369917403880122, -0.7304119112902326, -0.7319946059021527, -0.7335152479141738, -0.7360894053471763, -0.737769428640768, -0.731387363424685, -0.7367309937833552, -0.7320370155981712, -0.7279441513010028, -0.7250138945275664, -0.7337848257591061, -0.7326352521444232, -0.7400038548248322, -0.7392332115987239, -0.7405093703962085, -0.7358643508931615, -0.7351539856027046, -0.7375335233402863, -0.7320349535756222, -0.7323424862873349, -0.7311699278503041, -0.73193927876231, -0.7342158103987102, -0.7336204946558675, -0.7457767836140327, -0.7326466011283158, -0.7333395550300745, -0.7263509745326094, -0.7300685111276934, -0.7279331971579425, -0.7269824280558073, -0.732468462368618, -0.740703555151992, -0.7331808411162093, -0.7277691028452636, -0.731780886553205, -0.7393844510141019, -0.7499395253639408, -0.7428578113920056, -0.7329717655357243, -0.7348234318650635, -0.7353020235606976, -0.7321441823183813, -0.7358756250741296, -0.7290010998694725, -0.7332584396943456, -0.7214782320257888, -0.7393277232129095, -0.7457061313279473]
#listcorr = [-0.15533635530745185, -0.6261101458625491, -0.6283672933462191, -0.6261341715173672, -0.635904753096498, -0.6478975616358452, -0.6546675117782986, -0.6696253830703839, -0.6676424000841114, -0.6761717976171625, -0.6891460193743165, -0.6720522358315661, -0.6842409049998647, -0.6941483266183958, -0.6819605041356567, -0.6921307305692801, -0.6974118244250612, -0.6877276293682595, -0.6975180166936966, -0.699362900982982, -0.6900176483424889, -0.6930444490784223, -0.6900437932974185, -0.7022671734019181, -0.6917734057659254, -0.6850279494457204, -0.6889707768594764, -0.6932684998402032, -0.6877374177079576, -0.6984572192619203, -0.6977660925568185, -0.6919893299160746, -0.6963702609467773, -0.7110312711090508, -0.7205724517474444, -0.6988695095967887, -0.7103223178901148, -0.7066052462875619, -0.7183075818913138, -0.7154377489551932, -0.7088756137953657, -0.707082142138999, -0.7226954733123476, -0.7103618835652266, -0.710930690475186, -0.7217952963201721, -0.7193970614884093, -0.7259399976426528, -0.7133274757373838, -0.7128356151291262, -0.7154447977837326, -0.7271007631430586, -0.7161603834335195, -0.7127408203499865, -0.72103956071462, -0.7295909300855787, -0.7251813288910407, -0.723708742721878, -0.7291789132139994, -0.7321391799272989, -0.7238789685287154, -0.7239828388735304, -0.7290574486054026, -0.7190759055488052, -0.7268529379218275, -0.7295493327303769, -0.719326426117973, -0.7127832694690167, -0.7081343451222445, -0.7065131788206702, -0.715821841409185, -0.722080445540987, -0.7300130252264722, -0.7207281466845149, -0.7280898054612912, -0.720801798098683, -0.7250909568675997, -0.7119285039302476, -0.726113803005629, -0.7271415484249357, -0.7215975739756065, -0.7314755145354167]

#[-0.12449649274136408, -0.6062603034856566, -0.6500136906231077, -0.665846617119604, -0.6753861081067146, -0.6664562190666218, -0.6667163514579058, -0.6677145673780716, -0.6733931657497544, -0.6642309977853739, -0.6762375241131701, -0.6657130610420295, -0.6865755925943022, -0.6837810659116562, -0.6700516936195952, -0.6752976532611156, -0.6817794859651726, -0.6689651755970787, -0.6754815499454161, -0.6719773843663515, -0.6743921033546763, -0.6620539835005496, -0.6628016623641757, -0.6618985863573544, -0.6598807252062251, -0.6625214705599016, -0.6596807297099377, -0.6714477371322355, -0.6543929140642616, -0.6550635653767745, -0.6602128035194504, -0.6724478981494735, -0.6669570749113088, -0.6683566174672562, -0.6592368108638811, -0.658207849386008, -0.665492302728521, -0.6608526499665444, -0.6654522618175491, -0.6675901569014058, -0.6762387996028043, -0.666744283106389, -0.6753339916155052, -0.6678960452832354, -0.6629964628926014, -0.6632748434151133, -0.6571942245982588, -0.6532526269650967, -0.6575939531141508, -0.6661601456109744, -0.6558624414173732, -0.6614830897848514, -0.6527003560137032, -0.6571310855947846, -0.6499990413514403, -0.6604879805646495, -0.6507868943814908, -0.6489003953552108, -0.6545803504979687, -0.6590608327399711, -0.6569705744554973, -0.6610678119862169, -0.666294862274558, -0.6721486799477475, -0.6663188774259386, -0.662783078035613, -0.6633973276356492, -0.6653524100818637, -0.6678847224848474, -0.6636176913995172, -0.6699278967023471, -0.668728864823622, -0.6659932014708806, -0.672113370952686, -0.6628647581285507, -0.6704696169731219, -0.6684964885207803, -0.6704237290398645, -0.6652677264336183, -0.6514457779114874, -0.6617489202636864, -0.6670431774199223, -0.6661172381809445, -0.6712627734626344, -0.66156540532593, -0.6759450340022302, -0.6790018473996179, -0.6742071714975523, -0.6731648062174226, -0.6614081269255423, -0.670622608540417, -0.6780592653632741, -0.683346947678905, -0.6808910382678631, -0.6757462069565433, -0.6744922154701657, -0.6749052398873241, -0.6722165072636366, -0.6799184278028753, -0.67549830911357, -0.6857538466761102]


# listcorr = [-0.15533635530745185, -0.6261101458625491, -0.6283672933462191, -0.6261341715173672, -0.635904753096498, -0.6478975616358452, -0.6546675117782986, -0.6696253830703839, -0.6676424000841114, -0.6761717976171625, -0.6891460193743165, -0.6720522358315661, -0.6842409049998647, -0.6941483266183958, -0.6819605041356567, -0.6921307305692801, -0.6974118244250612, -0.6877276293682595, -0.6975180166936966, -0.699362900982982, -0.6900176483424889, -0.6930444490784223, -0.6900437932974185, -0.7022671734019181, -0.6917734057659254, -0.6850279494457204, -0.6889707768594764, -0.6932684998402032, -0.6877374177079576, -0.6984572192619203, -0.6977660925568185, -0.6919893299160746, -0.6963702609467773, -0.7110312711090508, -0.7205724517474444, -0.6988695095967887, -0.7103223178901148, -0.7066052462875619, -0.7183075818913138, -0.7154377489551932, -0.7088756137953657, -0.707082142138999, -0.7226954733123476, -0.7103618835652266, -0.710930690475186, -0.7217952963201721, -0.7193970614884093, -0.7259399976426528, -0.7133274757373838, -0.7128356151291262, -0.7154447977837326, -0.7271007631430586, -0.7161603834335195, -0.7127408203499865, -0.72103956071462, -0.7295909300855787, -0.7251813288910407, -0.723708742721878, -0.7291789132139994, -0.7321391799272989, -0.7238789685287154, -0.7239828388735304, -0.7290574486054026, -0.7190759055488052, -0.7268529379218275, -0.7295493327303769, -0.719326426117973, -0.7127832694690167, -0.7081343451222445, -0.7065131788206702, -0.715821841409185, -0.722080445540987, -0.7300130252264722, -0.7207281466845149, -0.7280898054612912, -0.720801798098683, -0.7250909568675997, -0.7119285039302476, -0.726113803005629, -0.7271415484249357, -0.7215975739756065, -0.7314755145354167, -0.7326754556309272, -0.7373561786281022, -0.7316186259389661, -0.7269711812549527, -0.7305438509156079, -0.7297602094360042, -0.7322278678679339, -0.7188402182964757, -0.7260092248413066, -0.7212380007861936, -0.7199928423040254, -0.7195487094977885, -0.7299812831306096, -0.7265617483745203, -0.7204584789650719, -0.7366704242122137, -0.7366728313150994, -0.7337813087867479, -0.730352655202939]


# k=10 [-0.26648180118083614, -0.7223233553226671, -0.7324858438787439, -0.7305311466938038, -0.7486682393029389, -0.7631776150152417, -0.7637782818085302, -0.7809091669299901, -0.7704439813975653, -0.7839998497251993]
# k=20 [-0.26715228863929175, -0.7821383078225999, -0.7892354306343122, -0.7887249646275445, -0.7956880202733846, -0.7971462679502518, -0.8007729561462269, -0.8038489872757816, -0.8015905657168207, -0.803000648687705, -0.790375610700385]


# print(len(listcorr))


import argparse
import torch
# import wandb
from OdorDataset import OdorMonoDataset
from utils.helpers import *
from methods import *
from optimizers import *
from torch.utils.data import DataLoader
from utils.visualization import *
import uuid
from utils.helpers import set_seeds
from sklearn.neighbors import kneighbors_graph
import scipy
from distances import (
    distance_matrix,
    euclidean_distance,
    poincare_distance,
    knn_geodesic_distance_matrix,
    knn_graph_weighted_adjacency_matrix,
    # hamming_distance_matrix
)


def hasone(node_index, dim_index):
    bin_i, bin_j = np.binary_repr(node_index), np.binary_repr(dim_index)
    length = len(bin_j)
    return (bin_i[:length] == bin_j) * 1


def get_tree_data(depth, dtype=np.float32):
    n = 2 ** depth - 1
    x = np.fromfunction(lambda i, j: np.vectorize(hasone)(i + 1, j + 1),
                        (n, n), dtype=np.int32).astype(dtype)
    # print(x.shape)
    return x, x


### If using Jupyter Notebook:###
# import sys
# if 'ipykernel_launcher' in sys.argv[0]:
#     sys.argv = sys.argv[:1]
###


def select_subjects(subjects, embeddings, labels, CIDs,subjects_ids,subject_id=None,n_subject=None):
    if subject_id is not None and n_subject is not None:
        raise ValueError('You can only provide either subject_id or n_subject')
    elif subject_id is not None:
        if type(subject_id) == int:


            embeddings = embeddings[subjects == subject_id]
            labels = labels[subjects == subject_id]
            CIDs = CIDs[subjects == subject_id]
            subjects = subjects[subjects == subject_id]
        else:
            embeddings = embeddings[np.isin(subjects, subject_id)]
            labels = labels[np.isin(subjects, subject_id)]
            CIDs = CIDs[np.isin(subjects, subject_id)]
            subjects = subjects[np.isin(subjects, subject_id)]

    elif n_subject is not None:
        # randomize subjects_id and select n_subjects
        subjects_ids = np.random.permutation(subjects_ids)
        print('subjects_ids', subjects_ids)
        n_subjects = subjects_ids[:n_subject]
        embeddings = embeddings[np.isin(subjects, n_subjects)]
        labels = labels[np.isin(subjects, n_subjects)]
        CIDs = CIDs[np.isin(subjects, n_subjects)]
        subjects = subjects[np.isin(subjects, n_subjects)]
    else:
        raise ValueError('Please provide either subject_id or n_subject')


    return embeddings, labels, CIDs, subjects


if __name__ == "__main__":

    parser = argparse.ArgumentParser('Hyperbolic Smell')
    parser.add_argument('--representation_name', type=str, default='molformer')
    parser.add_argument('--batch_size', type=int, default=240) #480 for sagar full
    parser.add_argument('--num_epochs', type=int, default=10001)
    # parser.add_argument('--min_dist', type=float, default=1.)
    parser.add_argument('--latent_dim', type=int, default=2)
    parser.add_argument('--lr', type=float, default=0.001)
    # parser.add_argument('--lr', type=float, default=0.001)
    parser.add_argument('--seed', type=int, default=1)
    parser.add_argument('--base_dir', type=str,
                        default='./data/')

    parser.add_argument('--dataset_name', type=str, default='sagar')  # tree for synthetic, gslf or sagar or keller for real
    parser.add_argument('--normalize', type=bool, default=True)  # only for Hyperbolic embeddings
    parser.add_argument('--optimizer', type=str, default='poincare', choices=['standard', 'poincare'])
    parser.add_argument('--model_name', type=str, default='contrastive', choices=['isomap', 'mds', 'contrastive'])
    parser.add_argument('--latent_dist_fun', type=str, default='poincare', choices=['euclidean', 'poincare'])
    parser.add_argument('--distr', type=str, default='hypergaussian', choices=['gaussian', 'hypergaussian'])
    parser.add_argument('--distance_method', type=str, default='euclidean',
                        choices=['geo', 'graph', 'hamming', 'euclidean'])
    parser.add_argument('--n_samples', type=int, default=200)
    parser.add_argument('--dim', type=int, default=768)
    parser.add_argument('--depth', type=int, default=6)  # Changed from bool to int
    parser.add_argument('--temperature', type=float, default=0.1)  # 10
    parser.add_argument('--n_neighbors', type=int, default=20) #10
    # args = argparse.Namespace()
    args = parser.parse_args()

    if torch.cuda.is_available():
        args.device = torch.device('cuda')
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
        print('Using GPU')
    else:
        args.device = torch.device('cpu')
        args.gpu_index = -1
        print('Using CPU')

    args.random_string = uuid.uuid4().hex
    dataset_name = args.dataset_name
    representation_name = args.representation_name
    num_epochs = args.num_epochs
    normalize = args.normalize
    latent_dim = args.latent_dim
    lr = args.lr
    seed = args.seed
    base_dir = args.base_dir
    optimizer = args.optimizer
    model_name = args.model_name
    latent_dist_fun = args.latent_dist_fun
    distr = args.distr
    distance_method = args.distance_method
    n_neighbors = args.n_neighbors
    temperature = args.temperature

    ### Overwrite the batchsize ###
    depth = args.depth
    args.batch_size = 2 ** args.depth - 1  # to get full batch
    batch_size = args.batch_size
    set_seeds(seed)

    if dataset_name == 'tree':
        embeddings, labels = get_tree_data(depth)
        labels = torch.tensor(labels)
        ## binary_tree is a dataset of binary sequences.
        ## The root of the tree is the node 0: binary_tree[0]
        ## groundtruth distance from node i to the root of the tree (i.e. shortest path distance from node i to the root): hamming_distance(binary_tree[0], binary_tree[i])
        ## For visualizations, one can color a node by its groundtruth distance to the tree.
    elif dataset_name == 'random':
        embeddings = torch.randn(n_samples, dim)
    else:
        input_embeddings = f'embeddings/{representation_name}/{dataset_name}_{representation_name}_embeddings_13_Apr17.csv'
        embeddings, labels,subjects,CIDs = read_embeddings(base_dir, select_descriptors(dataset_name), input_embeddings,
                                             grand_avg=False)
        print('embeddings', embeddings.shape)
        print('labels', labels.shape) 

        embeddings, labels, CIDs, subjects = select_subjects(subjects, embeddings, labels, CIDs,subjects.unique(),subject_id=[1,2,3],n_subject=None) # ,subject_id=None,n_subject=3)
        # embeddings, labels, CIDs, subjects = select_subjects(subjects, embeddings, labels, CIDs,subjects.unique(),subject_id=3,n_subject=None)
    dataset = OdorMonoDataset(embeddings, labels, transform=None)
    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)
    if latent_dist_fun != 'euclidean' and latent_dist_fun != 'poincare':
        raise ValueError('Latent distance function not recognized')
    if model_name == 'isomap':
        model = Isomap(len(dataset), latent_dim,
                       euclidean_distance if latent_dist_fun == 'euclidean' else poincare_distance)
    elif model_name == 'mds':
        model = MDS(len(dataset), latent_dim,
                    euclidean_distance if latent_dist_fun == 'euclidean' else poincare_distance)
    elif model_name == 'contrastive':
        model = Contrastive(len(dataset), latent_dim,
                            euclidean_distance if latent_dist_fun == 'euclidean' else poincare_distance, distr=distr)
    else:
        raise ValueError('Model not recognized')
    model = model.to(args.device)

    if optimizer == 'standard':
        optimizer = StandardOptim(model, lr=lr)
    elif optimizer == 'poincare':
        optimizer = PoincareOptim(model, lr=lr)
    else:
        raise ValueError('Optimizer not recognized')

    losses = []
    # wandb.watch(model)

    correlation_coefficients = []

    for i in range(num_epochs):
        total_loss = 0
        for idx, batch, label in data_loader:
            batch = batch.to(args.device)
            label = label.to(args.device)
            if normalize:
                model.normalize()
            else:
                model.normalize(normalization=False)
            if distance_method == 'graph':
                data_nn_matrix = knn_graph_weighted_adjacency_matrix(batch, n_neighbors=3, metric='minkowski')
                data_dist_matrix = (data_nn_matrix > 0).astype(int)
                data_dist_matrix = torch.tensor(data_dist_matrix)
            elif distance_method == 'geo':
                data_dist_matrix = knn_geodesic_distance_matrix(batch)
                if model_name == 'contrastive':
                    data_binary_dist_matrix = (data_dist_matrix <= 1.01).to(torch.int)
            elif distance_method == 'hamming':
                data_dist_matrix = hamming_distance_matrix(batch)
                if model_name == 'contrastive':
                    data_binary_dist_matrix = (data_dist_matrix <= 1.01).astype(int)
                    data_binary_dist_matrix = torch.tensor(data_binary_dist_matrix)
                data_dist_matrix = torch.tensor(data_dist_matrix)
            elif distance_method == 'euclidean':
                #data_dist_matrix = scipy.spatial.distance.cdist(batch, batch, metric='euclidean')
                data_dist_matrix = scipy.spatial.distance.cdist(label, label, metric='euclidean')
                
                # # Counting the numbers of zeros in descriptors
                # zero_counts = np.sum(labels.numpy() == 0, axis=0)  # Convert to NumPy array if it's a tensor               
                # plt.figure(figsize=(10, 6))
                # plt.bar(range(len(zero_counts)), zero_counts, color='blue', alpha=0.7)
                # plt.xlabel('Column Index')
                # plt.ylabel('Count of Zeros')
                # plt.title('Count of Zeros in Each Column of Labels')
                # plt.xticks(range(len(zero_counts)))  # Set x-ticks to be the column indices
                # plt.grid(axis='y')
                # plt.show()

                # import pdb; pdb.set_trace() # to enter debugging mode

                # # Plotting the histogram
                # histo = data_dist_matrix.flatten()
                # plt.hist(histo, bins=100)
                # plt.show()
                

                data_dist_matrix = torch.tensor(data_dist_matrix)
                # positive_pairs
                if model_name == 'contrastive':
                    data_binary_dist_matrix = kneighbors_graph(data_dist_matrix, n_neighbors=n_neighbors,
                                                               mode='connectivity', include_self=False).toarray()
                    # print(data_binary_dist_matrix.shape)
            else:
                data_dist_matrix = distance_matrix(batch, euclidean_distance)
            # if geodesic:
            #     data_dist_matrix = geo_distance(batch)
            # else:
            #     data_dist_matrix = dist_matrix(batch, Euclidean)
            # binary matrix
            optimizer.zero_grad()
            loss = model.loss_fun(data_dist_matrix, idx, data_binary_dist_matrix, temperature)
            loss.backward()

            optimizer.step(idx)
            total_loss += loss.item()
        print(f'Epoch {i}, loss: {total_loss / len(data_loader):.3f}')
        losses.append(total_loss / len(data_loader))
        # wandb.log({'loss': total_loss/len(data_loader)})
        # print('norms', vector_norm(model.embeddings, dim=-1).mean().item(), vector_norm(model.embeddings, dim=-1).max().item())
        # if i % 10 == 0:

        # laten_embeddings_norm= torch.norm(model.embeddings, dim=-1).cpu().detach().numpy()
        # e=scipy.spatial.distance.cdist(data_loader.dataset.embeddings, data_loader.dataset.embeddings, metric='hamming')*data_loader.dataset.embeddings.shape[-1]
        # scatterplot_2d(losses, model.embeddings.detach().cpu().numpy(), laten_embeddings_norm, args=args, data_dist_matrix=e)
        # if num_epochs > 100:
        if i % 100 == 0:  # 1000
            # save_embeddings(i, args, model.embeddings.detach().cpu().numpy(), losses=losses,
            #                 losses_neg=model.losses_neg if model_name == 'contrastive' else [],
            #                 losses_pos=model.losses_pos if model_name == 'contrastive' else []) #subjects=subjects
            scatterplot_2d(i, model.embeddings.detach().cpu().numpy(), dataset.labels.detach().cpu().numpy(),CIDs,subjects=subjects,color_ENTROPY=True, shape_subject=False,
                           save=True, args=args,
                           losses=losses, losses_neg=model.losses_neg if model_name == 'contrastive' else [],
                           losses_pos=model.losses_pos if model_name == 'contrastive' else [])
            
            entropy = softmax(dataset.labels.detach().cpu().numpy(), -1)
            c = -(entropy * np.log(entropy)).sum(-1)
            radius = poincare_distance(model.embeddings.detach().cpu(), torch.zeros((1, 2)))
            corr = np.corrcoef(radius, c)[0, 1]  # Get the correlation coefficient
            correlation_coefficients.append(corr)  # Store the correlation coefficient

    # # After the training loop, plot the correlation coefficient vs. epochs
    # plt.figure(figsize=(10, 6))
    # plt.plot(range(correlation_coefficients), correlation_coefficients, marker='o', color='blue', linestyle='-', linewidth=2)
    # plt.xlabel('Epoch', fontsize=14)
    # plt.ylabel('Correlation Coefficient', fontsize=14)
    # plt.title('Correlation Coefficient vs. Number of Epochs', fontsize=16)
    # plt.grid(True)
    # plt.tight_layout()
    # # Save the correlation coefficient plot
    # plt.savefig('figs2/correlation_coefficient_vs_epochs.png')
    # plt.close() 
            print(correlation_coefficients)
            
            # scatterplot_2d_loss(i, model.embeddings.detach(), save=True, args=args,
            #                losses=losses, losses_neg=model.losses_neg if model_name == 'contrastive' else [],
            #                losses_pos=model.losses_pos if model_name == 'contrastive' else [])




        #     scatterplot_2d_subjectshape(i, model.embeddings.detach().cpu().numpy(), dataset.labels.detach().cpu().numpy(), subjects,
        #                                 save=True, args=args,
        #                                 losses=losses, losses_neg=model.losses_neg if model_name == 'contrastive' else [],
        #                                 losses_pos=model.losses_pos if model_name == 'contrastive' else [])
        #     scatterplot_2d_subjectshape(i, model.embeddings.detach().cpu().numpy(), dataset.labels.detach().cpu().numpy(), subjects,
        #                                 save=True, args=args,
        #                                 losses=losses, losses_neg=model.losses_neg if model_name == 'contrastive' else [],
        #                                 losses_pos=model.losses_pos if model_name == 'contrastive' else [])
        # # if i % (num_epochs - 1) == 0 and i != 0:
        #     save_embeddings(i, args, model.embeddings.detach().cpu().numpy(), losses=losses,
        #                     losses_neg=model.losses_neg if model_name == 'contrastive' else [],
        #                     losses_pos=model.losses_pos if model_name == 'contrastive' else [])
        #     scatterplot_2d(i, model.embeddings.detach().cpu().numpy(), dataset.labels.detach().cpu().numpy(), save=True,
        #                    args=args,
        #                    losses=losses, losses_neg=model.losses_neg if model_name == 'contrastive' else [],
        #                    losses_pos=model.losses_pos if model_name == 'contrastive' else [])

